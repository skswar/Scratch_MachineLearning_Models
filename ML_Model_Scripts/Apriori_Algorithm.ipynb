{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163af5d4",
   "metadata": {},
   "source": [
    "# Apriori Algorithm From Scratch with Transaction Reduction Improvement\n",
    "## Author: Sayan Swar;     Email: sswar@ur.rochester.edu\n",
    "### Data Set: https://archive.ics.uci.edu/ml/datasets/adult\n",
    "\n",
    " ____________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "77020a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import itertools \n",
    "from itertools import product\n",
    "import time\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4290cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship',\n",
    "            'race','sex','capital-gain','capital-loss','hours-per-week','native-country','Income']\n",
    "\n",
    "#reading the data file\n",
    "df = pd.read_csv('adult.data', header=None, names=colnames)\n",
    "\n",
    "#removing all unnecessary columns\n",
    "df = df.drop('age', axis=1)\n",
    "df = df.drop('fnlwgt', axis=1)\n",
    "df = df.drop('capital-gain', axis=1)\n",
    "df = df.drop('capital-loss', axis=1)\n",
    "df = df.drop('hours-per-week', axis=1)\n",
    "df = df.drop('education-num', axis=1)\n",
    "\n",
    "#getting the count of each individual item in the data set\n",
    "itemset1 = {}\n",
    "for cols in list(df):\n",
    "    itemset1.update(df[cols].value_counts())\n",
    "\n",
    "#creating a new column called attribute set in the dataframe which holds all the concatenated values of a single\n",
    "#transaction in a list\n",
    "df['attribute_set'] = df.values.tolist()\n",
    "#df['isFlaggedToDelete'] = 1\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "430b9551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16280.5, 32561)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deciding the minimum support to be 0.5. Calulating the value of support count based on min support.\n",
    "min_support = 0.5\n",
    "number_of_transaction = len(df)\n",
    "support_count = number_of_transaction * min_support\n",
    "support_count,number_of_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1cfb65f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' United-States': 29170,\n",
       " ' White': 27816,\n",
       " ' <=50K': 24720,\n",
       " ' Private': 22696,\n",
       " ' Male': 21790}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating itemset 1. Removing all those items which doesnt follow the min support count.\n",
    "#the calculated itemset 1 will be used to calculate next itemsets.\n",
    "candidateset_1 =  pd.DataFrame(list(itemset1.items()), columns = ['Items','Counts'])\n",
    "\n",
    "candidateset_1_with_frequentitems = candidateset_1[candidateset_1['Counts']>=support_count]\n",
    "candidateset_1_with_frequentitems = candidateset_1_with_frequentitems.sort_values(by=['Counts'],ascending=0)\n",
    "candidateset_1_with_frequentitems['Items'] = candidateset_1_with_frequentitems['Items'].astype('str')\n",
    "candidateset_1_with_frequentitems_set = set(candidateset_1_with_frequentitems.loc[:,'Items'])\n",
    "candidateset_1_with_frequentitems_set_dict = dict(candidateset_1_with_frequentitems.values)\n",
    "candidateset_1_with_frequentitems_set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "37323c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function which can create all the required combinatons (Lk ad Ck) from itemset 2.\n",
    "def find_k_itemsets(itemset,itemsetcount,df,support_count):\n",
    "    \n",
    "    candidateset_with_frequentitems_list = sorted(list(itemset.keys()))\n",
    "    itemset_count = itemsetcount\n",
    "    i=0\n",
    "    itemsetk_set = set()\n",
    "    len_of_frequentsetk = len(candidateset_with_frequentitems_list)\n",
    "    for i in range(len_of_frequentsetk):\n",
    "        for j in range(i+1,len_of_frequentsetk):\n",
    "            if j<=len_of_frequentsetk:\n",
    "                if itemset_count<3:\n",
    "                    l1 = [candidateset_with_frequentitems_list[i]]\n",
    "                    l2 = [candidateset_with_frequentitems_list[j]]\n",
    "                else:\n",
    "                    l1 = sorted(candidateset_with_frequentitems_list[i])\n",
    "                    l2 = sorted(candidateset_with_frequentitems_list[j])\n",
    "                joinitems = set(l2).union(set(l1))\n",
    "                joinitems = sorted(joinitems)\n",
    "                if len(joinitems) == itemset_count:\n",
    "                    itemsetk_set.add(tuple(joinitems))\n",
    "        \n",
    "##creating subsets and checking if each of the subsets were frequent in the previous step or not\n",
    "##if not frquent in the previous step, then we are completely discarding the new itemset...........................\n",
    "    itemsetk_set_improved = set()\n",
    "    if itemset_count>2:\n",
    "        for item in itemsetk_set:\n",
    "            x = list(itertools.combinations(item, itemset_count-1))\n",
    "            check = all(things in sorted(list(candidateset_with_frequentitems_list)) for things in sorted(x))\n",
    "            if check==True:\n",
    "                itemsetk_set_improved.add(tuple(item))\n",
    "    else:\n",
    "        itemsetk_set_improved = itemsetk_set\n",
    "##subset creation ends..................................................................................................\n",
    "    \n",
    "    len_itemsetk = len(itemsetk_set_improved)\n",
    "    frequecy_count = 0\n",
    "    frequency_itemsetk = {}\n",
    "    ind = list() #transaction reduction code part\n",
    "    for i in range(0,len_itemsetk):\n",
    "        frequecy_count = 0\n",
    "        for j in df.index:\n",
    "            check = all(item in df.loc[j,'attribute_set'] for item in list(itemsetk_set_improved)[i])\n",
    "            if check is True:\n",
    "                frequecy_count += 1\n",
    "                frequency_itemsetk[list(itemsetk_set_improved)[i]] = frequecy_count\n",
    "                ##df.loc[j,'isFlaggedToDelete'] = 0\n",
    "                ind.append(j) #transaction reduction code part as an improvement\n",
    "    \n",
    "    frequency_itemsetk_filtered = {key:value for (key, value) in frequency_itemsetk.items() if value >= support_count}\n",
    "    return frequency_itemsetk_filtered,list(set(ind)) #transaction reduction code part, returning ind\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6825e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561\n",
      "32290\n",
      "28820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.628982067108154"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "frequency_itemsetk_filtered_final_list = {}\n",
    "frequency_itemsetk_filtered_final_list.update(candidateset_1_with_frequentitems_set_dict)\n",
    "temp_dict = {}\n",
    "temp_dict = candidateset_1_with_frequentitems_set_dict\n",
    "updated_df = df\n",
    "for i in range (2,number_of_transaction+1):\n",
    "    if len(temp_dict)>1:\n",
    "        print(len(updated_df))\n",
    "        k_filtered_itemset,ind = find_k_itemsets(temp_dict,i,updated_df,support_count) #transaction reduction code part, returning ind\n",
    "        updated_df = updated_df.loc[ind] #transaction reduction code part\n",
    "        temp_dict = {}\n",
    "        temp_dict = k_filtered_itemset\n",
    "        frequency_itemsetk_filtered_final_list.update(k_filtered_itemset)\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "end = time.time()        \n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a3805ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' United-States': 29170,\n",
       " ' White': 27816,\n",
       " ' <=50K': 24720,\n",
       " ' Private': 22696,\n",
       " ' Male': 21790,\n",
       " (' Private', ' White'): 19404,\n",
       " (' United-States', ' White'): 25621,\n",
       " (' Private', ' United-States'): 20135,\n",
       " (' Male', ' White'): 19174,\n",
       " (' <=50K', ' Private'): 17733,\n",
       " (' <=50K', ' White'): 20699,\n",
       " (' <=50K', ' United-States'): 21999,\n",
       " (' Male', ' United-States'): 19488,\n",
       " (' Private', ' United-States', ' White'): 17728,\n",
       " (' <=50K', ' United-States', ' White'): 18917,\n",
       " (' Male', ' United-States', ' White'): 17653}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_itemsetk_filtered_final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d01fa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency_itemsetk_filtered_final_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
